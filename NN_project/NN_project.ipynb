{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ef9e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined records: 69\n"
     ]
    }
   ],
   "source": [
    "import ndjson\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Open and read the NDJSON file\n",
    "with open('D:\\\\machine project\\\\video-input\\\\videos.ndjson', 'r') as f:\n",
    "    data = ndjson.load(f)\n",
    "\n",
    "\n",
    "print(f\"Combined records: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809fb392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cmhpke9p4cjbs0782sob057xx.mp4</td>\n",
       "      <td>[{'value': 'Surprised'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cmhpke9p4cjbt0782363n2x0u.mp4</td>\n",
       "      <td>[{'value': 'Surprised'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cmhpke9p4cjbu0782assgc5x9.mp4</td>\n",
       "      <td>[{'value': 'Surprised'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cmhpke9p4cjbv0782ah5bfrg4.mp4</td>\n",
       "      <td>[{'value': 'Surprised'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cmhpke9p4cjbw0782wkp7yx3s.mp4</td>\n",
       "      <td>[{'value': 'Surprised'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id                   emotion\n",
       "0  cmhpke9p4cjbs0782sob057xx.mp4  [{'value': 'Surprised'}]\n",
       "1  cmhpke9p4cjbt0782363n2x0u.mp4  [{'value': 'Surprised'}]\n",
       "2  cmhpke9p4cjbu0782assgc5x9.mp4  [{'value': 'Surprised'}]\n",
       "3  cmhpke9p4cjbv0782ah5bfrg4.mp4  [{'value': 'Surprised'}]\n",
       "4  cmhpke9p4cjbw0782wkp7yx3s.mp4  [{'value': 'Surprised'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.DataFrame(data)\n",
    "df_meta.drop(columns=['media_attributes'], inplace=True)\n",
    "df_meta['data_row'] = df_meta['data_row'].astype(str).str[8:37]\n",
    "df_meta.rename(columns={'data_row': 'id'}, inplace=True)\n",
    "df_meta.rename(columns={'metadata_fields': 'emotion'}, inplace=True)\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbeafb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "\n",
      "Unique emotions found:\n",
      "['surprised' 'sad' 'neutral' 'happy' 'disgust' 'angry']\n"
     ]
    }
   ],
   "source": [
    "# --- ROBUST DATA CLEANING ---\n",
    "def clean_emotion_col(x):\n",
    "    # 1. If it's a list (e.g., ['angry']), grab the first item\n",
    "    if isinstance(x, list):\n",
    "        if len(x) > 0:\n",
    "            x = x[0]\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "\n",
    "    # 2. If it's a dictionary (e.g., {'label': 'angry'}), grab the value\n",
    "    if isinstance(x, dict):\n",
    "        # Try common keys, or just grab the first value found\n",
    "        x = x.get('label', x.get('emotion', list(x.values())[0]))\n",
    "\n",
    "    # 3. Convert whatever is left to a string and lower-case it\n",
    "    text = str(x).lower()\n",
    "    \n",
    "    # 4. Remove any leftover garbage characters\n",
    "    text = text.replace(\"'\", \"\").replace('\"', \"\").strip()\n",
    "    return text\n",
    "\n",
    "# Apply the fix\n",
    "print(\"Cleaning data...\")\n",
    "df_meta['emotion'] = df_meta['emotion'].apply(clean_emotion_col)\n",
    "# --- VERIFY ---\n",
    "print(\"\\nUnique emotions found:\")\n",
    "print(df_meta['emotion'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c7b40d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Face Detector loaded successfully from: C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\n",
      "ğŸšœ Starting HD Harvest from 69 videos...\n",
      "âœ… HD Harvest Complete!\n",
      "   Scanned 4677 total frames.\n",
      "   Saved 4669 high-quality face images to 'data/processed_frames_HD'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "video_folder = \"D:\\\\machine project\\\\data\\\\videos\"\n",
    "output_folder = \"data/processed_frames_HD\" \n",
    "img_size = (128, 128) \n",
    "\n",
    "# --- FIX IS HERE ---\n",
    "# 1. Define the path\n",
    "cascade_path = r\"C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# 2. Check if file exists (Crucial because Windows paths can be tricky)\n",
    "if not os.path.exists(cascade_path):\n",
    "    print(f\"âŒ ERROR: Cannot find the Cascade XML at: {cascade_path}\")\n",
    "    print(\"   Please check the path again.\")\n",
    "    exit()\n",
    "\n",
    "# 3. Actually LOAD the classifier object\n",
    "face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "# Verify it loaded correctly\n",
    "if face_cascade.empty():\n",
    "    print(\"âŒ ERROR: Cascade file found but failed to load. Is it corrupt?\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"âœ… Face Detector loaded successfully from: {cascade_path}\")\n",
    "\n",
    "\n",
    "# --- START HARVESTING ---\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "print(f\"ğŸšœ Starting HD Harvest from {len(df_meta)} videos...\")\n",
    "\n",
    "count = 0\n",
    "faces_found_count = 0\n",
    "\n",
    "for index, row in df_meta.iterrows():\n",
    "    video_filename = row['id']\n",
    "    emotion_label = row['emotion']\n",
    "    \n",
    "    # Check extension\n",
    "    if not video_filename.endswith('.mp4'):\n",
    "        video_filename += \".mp4\"\n",
    "        \n",
    "    video_path = os.path.join(video_folder, video_filename)\n",
    "    \n",
    "    # Skip if video file missing\n",
    "    if not os.path.exists(video_path):\n",
    "        continue\n",
    "\n",
    "    # Create Emotion Folder\n",
    "    label_path = os.path.join(output_folder, emotion_label)\n",
    "    os.makedirs(label_path, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # 1. Convert to Gray (Face detection needs grayscale)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 2. Detect Faces\n",
    "        # scaleFactor=1.1 -> Scans image at different sizes (10% increments)\n",
    "        # minNeighbors=4  -> Higher = fewer false positives, but might miss faces\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
    "        \n",
    "        # 3. If a face is found, crop it\n",
    "        if len(faces) > 0:\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Crop: [y_start:y_end, x_start:x_end]\n",
    "                face_img = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                try:\n",
    "                    # High Quality Resize\n",
    "                    face_resized = cv2.resize(face_img, img_size, interpolation=cv2.INTER_AREA)\n",
    "                    \n",
    "                    # Save\n",
    "                    clean_name = video_filename.replace('.mp4', '')\n",
    "                    save_name = f\"{clean_name}_f{frame_id}.jpg\"\n",
    "                    cv2.imwrite(os.path.join(label_path, save_name), face_resized)\n",
    "                    \n",
    "                    faces_found_count += 1\n",
    "                except Exception as e:\n",
    "                    pass # Skip if resize crashes (rare)\n",
    "                \n",
    "                # Only take the first face to avoid duplicates/crowd\n",
    "                break \n",
    "        \n",
    "        frame_id += 1\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "print(f\"âœ… HD Harvest Complete!\")\n",
    "print(f\"   Scanned {count} total frames.\")\n",
    "print(f\"   Saved {faces_found_count} high-quality face images to '{output_folder}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147d2c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading Training Data from data/processed_frames_HD...\n",
      "Found 3622 images belonging to 6 classes.\n",
      "ğŸ“‚ Loading Validation Data from data/processed_frames_HD...\n",
      "Found 903 images belonging to 6 classes.\n",
      "ğŸš€ Starting Training on HD Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 227ms/step - accuracy: 0.4412 - loss: 1.4205 - val_accuracy: 0.5194 - val_loss: 1.3153\n",
      "Epoch 2/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.6676 - loss: 0.9010 - val_accuracy: 0.6002 - val_loss: 1.0317\n",
      "Epoch 3/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.7852 - loss: 0.5919 - val_accuracy: 0.6600 - val_loss: 1.0751\n",
      "Epoch 4/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.8490 - loss: 0.4146 - val_accuracy: 0.5703 - val_loss: 1.4805\n",
      "Epoch 5/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.8876 - loss: 0.3203 - val_accuracy: 0.6412 - val_loss: 1.3061\n",
      "Epoch 6/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.9194 - loss: 0.2351 - val_accuracy: 0.5327 - val_loss: 2.0926\n",
      "Epoch 7/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9224 - loss: 0.2223 - val_accuracy: 0.6711 - val_loss: 1.6405\n",
      "Epoch 8/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.9268 - loss: 0.2050 - val_accuracy: 0.7065 - val_loss: 1.3381\n",
      "Epoch 9/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.9495 - loss: 0.1403 - val_accuracy: 0.7287 - val_loss: 1.2579\n",
      "Epoch 10/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.9464 - loss: 0.1516 - val_accuracy: 0.6678 - val_loss: 1.6322\n",
      "Epoch 11/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.9569 - loss: 0.1253 - val_accuracy: 0.6932 - val_loss: 1.7522\n",
      "Epoch 12/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.9613 - loss: 0.1110 - val_accuracy: 0.7564 - val_loss: 1.4568\n",
      "Epoch 13/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.9691 - loss: 0.1035 - val_accuracy: 0.6523 - val_loss: 1.4282\n",
      "Epoch 14/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9671 - loss: 0.0949 - val_accuracy: 0.6944 - val_loss: 1.6122\n",
      "Epoch 15/15\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9749 - loss: 0.0822 - val_accuracy: 0.7530 - val_loss: 2.0347\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# We use the HD folder for BOTH training and validation\n",
    "dataset_path = \"data/processed_frames_HD\" \n",
    "img_height, img_width = 128, 128  # Match the size you harvested!\n",
    "\n",
    "# 1. LOAD DATA\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,      # Normalize\n",
    "    validation_split=0.2  # 20% split\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“‚ Loading Training Data from {dataset_path}...\")\n",
    "train_ds = datagen.flow_from_directory(\n",
    "    dataset_path,             # FIXED PATH\n",
    "    target_size=(img_height, img_width), # FIXED SIZE (128x128)\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“‚ Loading Validation Data from {dataset_path}...\")\n",
    "val_ds = datagen.flow_from_directory(\n",
    "    dataset_path,             # FIXED PATH\n",
    "    target_size=(img_height, img_width), # FIXED SIZE (128x128)\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# 2. DEFINE MODEL (Updated for 128x128 input)\n",
    "model = Sequential([\n",
    "    # --- CNN PART ---\n",
    "    # Input Shape is now 128x128x3\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    # Optional: Add a 4th layer since 128x128 is deeper\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    # --- FCN PART ---\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Output\n",
    "    Dense(train_ds.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# 3. TRAIN\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"ğŸš€ Starting Training on HD Data...\")\n",
    "history = model.fit(train_ds, epochs=15, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c161863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4820a22dd0244316a3674b9e6e0e3776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "custom_interface.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PC\\.cache\\huggingface\\hub\\models--speechbrain--emotion-recognition-wav2vec2-IEMOCAP. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec26320f8bb74b508ef90d0f1f9a555a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hyperparams.yaml: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\inspect.py:1007: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\integrations\\k2_fsa\\__init__.py\", line 12, in <module>\n",
      "    import k2  # noqa\n",
      "    ^^^^^^^^^\n",
      "ModuleNotFoundError: No module named 'k2'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 97, in ensure_module\n",
      "    self.lazy_module = importlib.import_module(self.target)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\integrations\\k2_fsa\\__init__.py\", line 16, in <module>\n",
      "    raise ImportError(MSG) from e\n",
      "ImportError: Please install k2 to use k2\n",
      "Checkout: https://k2-fsa.github.io/k2/installation/from_wheels.html\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\pydoc.py\", line 466, in safeimport\n",
      "    module = importlib.import_module(path)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1316, in _find_and_load_unlocked\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 112, in __getattr__\n",
      "    return getattr(self.ensure_module(1), attr)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 172, in ensure_module\n",
      "    module = super().ensure_module(stacklevel + 1)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 80, in ensure_module\n",
      "    importer_frame = inspect.getframeinfo(sys._getframe(stacklevel + 1))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\inspect.py\", line 1710, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\inspect.py\", line 970, in getsourcefile\n",
      "    module = getmodule(object, filename)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\inspect.py\", line 1007, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 112, in __getattr__\n",
      "    return getattr(self.ensure_module(1), attr)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 172, in ensure_module\n",
      "    module = super().ensure_module(stacklevel + 1)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 103, in ensure_module\n",
      "    raise ImportError(f\"Lazy import of {repr(self)} failed\") from e\n",
      "ImportError: Lazy import of LazyModule(package=None, target=speechbrain.integrations.k2_fsa, loaded=False) failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_8692\\3818578077.py\", line 2, in <module>\n",
      "    classifier = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\", pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\inference\\interfaces.py\", line 111, in foreign_class\n",
      "    return pretrained_from_hparams(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\inference\\interfaces.py\", line 193, in pretrained_from_hparams\n",
      "    hparams = load_hyperpyyaml(fin, overrides, overrides_must_match)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\hyperpyyaml\\core.py\", line 188, in load_hyperpyyaml\n",
      "    hparams = yaml.load(yaml_stream, Loader=loader)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\yaml\\__init__.py\", line 81, in load\n",
      "    return loader.get_single_data()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ruamel\\yaml\\constructor.py\", line 119, in get_single_data\n",
      "    return self.construct_document(node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ruamel\\yaml\\constructor.py\", line 123, in construct_document\n",
      "    data = self.construct_object(node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ruamel\\yaml\\constructor.py\", line 150, in construct_object\n",
      "    data = self.construct_non_recursive_object(node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ruamel\\yaml\\constructor.py\", line 191, in construct_non_recursive_object\n",
      "    for _dummy in generator:\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ruamel\\yaml\\constructor.py\", line 629, in construct_yaml_map\n",
      "    value = self.construct_mapping(node)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ruamel\\yaml\\constructor.py\", line 425, in construct_mapping\n",
      "    return BaseConstructor.construct_mapping(self, node, deep=deep)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ruamel\\yaml\\constructor.py\", line 247, in construct_mapping\n",
      "    value = self.construct_object(value_node, deep=deep)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ruamel\\yaml\\constructor.py\", line 150, in construct_object\n",
      "    data = self.construct_non_recursive_object(node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ruamel\\yaml\\constructor.py\", line 186, in construct_non_recursive_object\n",
      "    data = constructor(self, tag_suffix, node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\hyperpyyaml\\core.py\", line 470, in _construct_object\n",
      "    callable_ = pydoc.locate(callable_string)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\pydoc.py\", line 1804, in locate\n",
      "    nextmodule = safeimport('.'.join(parts[:n+1]), forceload)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\pydoc.py\", line 480, in safeimport\n",
      "    raise ErrorDuringImport(path, err)\n",
      "pydoc.ErrorDuringImport: problem in speechbrain.lobes.models.huggingface_transformers.wav2vec2 - ImportError: Lazy import of LazyModule(package=None, target=speechbrain.integrations.k2_fsa, loaded=False) failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\integrations\\k2_fsa\\__init__.py\", line 12, in <module>\n",
      "    import k2  # noqa\n",
      "    ^^^^^^^^^\n",
      "ModuleNotFoundError: No module named 'k2'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 97, in ensure_module\n",
      "    self.lazy_module = importlib.import_module(self.target)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\integrations\\k2_fsa\\__init__.py\", line 16, in <module>\n",
      "    raise ImportError(MSG) from e\n",
      "ImportError: Please install k2 to use k2\n",
      "Checkout: https://k2-fsa.github.io/k2/installation/from_wheels.html\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2194, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1188, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1059, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 867, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 752, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, context, tb_offset) if etb else []\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 825, in get_records\n",
      "    mod = inspect.getmodule(cf.tb_frame)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\inspect.py\", line 1007, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 112, in __getattr__\n",
      "    return getattr(self.ensure_module(1), attr)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 172, in ensure_module\n",
      "    module = super().ensure_module(stacklevel + 1)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\importutils.py\", line 103, in ensure_module\n",
      "    raise ImportError(f\"Lazy import of {repr(self)} failed\") from e\n",
      "ImportError: Lazy import of LazyModule(package=None, target=speechbrain.integrations.k2_fsa, loaded=False) failed\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.inference.interfaces import foreign_class\n",
    "classifier = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\", pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")\n",
    "out_prob, score, index, text_lab = classifier.classify_file(\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP/anger.wav\")\n",
    "print(text_lab)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
